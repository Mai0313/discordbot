from io import BytesIO
import base64
import datetime

from openai import AsyncStream, BadRequestError
import logfire
import nextcord
from nextcord import Locale, Interaction, SlashOption
from nextcord.ext import commands
from openai.types.responses import ResponseStreamEvent
from openai.types.responses.tool_param import ImageGeneration
from openai.types.responses.web_search_tool_param import WebSearchToolParam

from discordbot.sdk.llm import LLMSDK

available_models = [
    "openai/gpt-4o",
    "openai/gpt-5-mini",
    "openai/gpt-5-nano",
    "claude-3-5-haiku-20241022",
]
MODEL_CHOICES = {available_model: available_model for available_model in available_models}

_TOOLS = [
    WebSearchToolParam(type="web_search_preview"),
    ImageGeneration(type="image_generation"),  # åœ–ç‰‡å¯èƒ½å¾ˆè²´ çœ‹æƒ…æ³è§£æ±º
]


class ReplyGeneratorCogs(commands.Cog):
    def __init__(self, bot: commands.Bot) -> None:
        """Initialize the ReplyGeneratorCogs.

        Args:
            bot (commands.Bot): The bot instance.
        """
        self.bot = bot
        # å„²å­˜æ¯å€‹ç”¨æˆ¶çš„ä¸Šä¸€å€‹ response IDï¼Œç”¨æ–¼å°è©±è¨˜æ†¶
        self.user_last_response_id: dict[int, str] = {}

    async def _get_attachment_list(
        self, messages: list[nextcord.Message] | None = None
    ) -> list[str]:
        """Retrieve all attachments from a message.

        This function extracts image attachment URLs, embed descriptions, and converts sticker images to base64 encoded strings. If the message is None, an empty list is returned.

        Args:
            messages (Optional[list[nextcord.Message]]): The message from which to extract attachments.

        Returns:
            List[str]: A list containing the attachment URLs and base64 encoded sticker images.
        """
        if messages is None:
            messages = []
        attachments: list[str] = []
        for message in messages:
            if message.attachments:
                _attach = [attachment.url for attachment in message.attachments if attachment.url]
                if _attach:
                    attachments.extend(_attach)
            if message.embeds:
                _attach = [embed.description for embed in message.embeds if embed.description]
                if _attach:
                    attachments.extend(_attach)
            if message.stickers:
                _attach = [sticker.url for sticker in message.stickers]
                if _attach:
                    attachments.extend(_attach)
        return attachments

    @nextcord.slash_command(
        name="oai",
        description="I can reply from hints, search the web, or draw.",
        name_localizations={Locale.zh_TW: "ç”Ÿæˆ", Locale.ja: "ç”Ÿæˆ"},
        description_localizations={
            Locale.zh_TW: "æˆ‘å¯ä»¥å›žç­”å•é¡Œ, ä¸Šç¶²æœå°‹, ä¹Ÿå¯ä»¥ç•«åœ–",
            Locale.ja: "æç¤ºã«åŸºã¥ã„ã¦è¿”ç­”ã‚’ç”Ÿæˆã—ã€æ¤œç´¢ã‚„æç”»ã‚‚ã§ãã¾ã™ã€‚",
        },
        dm_permission=True,
        nsfw=False,
    )
    async def oai(
        self,
        interaction: Interaction,
        prompt: str = SlashOption(
            description="Enter your prompt.",
            description_localizations={
                Locale.zh_TW: "è«‹è¼¸å…¥æç¤ºè©žã€‚",
                Locale.ja: "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
            },
        ),
        model: str = SlashOption(
            description="Choose a model (default: GPT-5).",
            description_localizations={
                Locale.zh_TW: "é¸æ“‡æ¨¡åž‹ (é è¨­ç‚º GPT-5)",
                Locale.ja: "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠžã—ã¦ãã ã•ã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ GPT-5ï¼‰",
            },
            choices=MODEL_CHOICES,
            required=False,
            default=available_models[0],
        ),
        image: nextcord.Attachment | None = SlashOption(  # noqa: B008
            description="(Optional) Upload an image.",
            description_localizations={
                Locale.zh_TW: "ï¼ˆå¯é¸ï¼‰ä¸Šå‚³ä¸€å¼µåœ–ç‰‡ã€‚",
                Locale.ja: "ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
            },
            required=False,
        ),
    ) -> None:
        """Generate a reply based on the user's prompt.

        If the model 'o1' is selected along with an image, an error message is returned since 'o1' does not support image input.
        The function can either generate a complete response or stream the response in real-time based on the stream parameter.

        Args:
            interaction (Interaction): The interaction object for the command.
            prompt (str): The prompt text provided by the user.
            model (str): The selected model, defaults to "gpt-5" if not specified.
            image (Optional[nextcord.Attachment]): An optional image attachment uploaded by the user.
        """
        await interaction.response.defer()
        attachments = []
        if model not in ["o1", "o1-mini"] and image:
            attachments.append(image.url)

        # åˆå§‹ç‹€æ…‹è¨Šæ¯
        await interaction.followup.send(content="ðŸ¤” æ€è€ƒä¸­...")

        try:
            llm_sdk = LLMSDK(model=model)
            content = await llm_sdk.prepare_response_content(
                prompt=prompt, attachments=attachments
            )
            # æº–å‚™ streaming è«‹æ±‚
            try:
                # ç²å–ç”¨æˆ¶çš„æœ€æ–° response ID
                previous_response_id = self.user_last_response_id.get(interaction.user.id, None)
                stream = await llm_sdk.client.responses.create(
                    model=model,
                    tools=_TOOLS,
                    input=[{"role": "user", "content": content}],
                    stream=True,
                    previous_response_id=previous_response_id,
                )
            except BadRequestError:
                # å¦‚æžœ API å›žå‚³éŒ¯èª¤ï¼ˆresponse ID ç„¡æ•ˆï¼‰ï¼Œæ¸…ç†è©²ç”¨æˆ¶è¨˜éŒ„ä¸¦é‡æ–°å˜—è©¦
                self.user_last_response_id.pop(interaction.user.id, None)
                stream = await llm_sdk.client.responses.create(
                    model=model,
                    tools=_TOOLS,
                    input=[{"role": "user", "content": content}],
                    stream=True,
                )

            await self._handle_streaming_response(
                interaction=interaction, stream=stream, prompt=prompt, update_per_words=10
            )

        except Exception as e:
            await interaction.edit_original_message(
                content=f"{interaction.user.mention}\nâŒ éŒ¯èª¤:\n{e}"
            )
            logfire.error("Error in oai", _exc_info=True)

    async def _handle_streaming_response(
        self,
        interaction: Interaction,
        stream: AsyncStream[ResponseStreamEvent],
        prompt: str,
        update_per_words: int = 10,
    ) -> None:
        """è™•ç† streaming å›žæ‡‰ï¼Œæ¯ 10 å€‹å­—æ›´æ–°ä¸€æ¬¡è¨Šæ¯ã€‚"""
        accumulated_text = ""
        accumulated_image = ""

        char_count = 0
        async for event in stream:
            # è™•ç†å®Œæˆäº‹ä»¶ï¼Œç²å– response ID
            if event.type == "response.completed":
                self.user_last_response_id[interaction.user.id] = event.response.id
                continue

            # è™•ç†æ–‡å­—ä¸²æµ
            if event.type == "response.output_text.delta":
                accumulated_text += event.delta
                char_count += len(event.delta)
                # æ¯ X å€‹å­—æ›´æ–°ä¸€æ¬¡è¨Šæ¯
                if char_count >= update_per_words:
                    await interaction.edit_original_message(
                        content=f"{interaction.user.mention}\n{accumulated_text}"
                    )
                    char_count = 0

            # è™•ç†åœ–ç‰‡ç”Ÿæˆä¸²æµ
            if event.type == "response.image_generation_call.partial_image":
                accumulated_image += event.partial_image_b64
                await self._display_image(
                    interaction=interaction,
                    text=accumulated_text,
                    image_base64=event.partial_image_b64,
                    prompt=prompt,
                )

        await interaction.edit_original_message(
            content=f"{interaction.user.mention}\n{accumulated_text}"
        )
        # æ–‡å­—ä¸€å®šæœƒæœ‰ åœ–ç‰‡ä¸ä¸€å®š
        if accumulated_image:
            await self._display_image(
                interaction=interaction,
                text=accumulated_text,
                image_base64=accumulated_image,
                prompt=prompt,
            )

    async def _display_image(
        self, interaction: Interaction, text: str, image_base64: str, prompt: str
    ) -> None:
        """é¡¯ç¤ºæœ€çµ‚å®Œæ•´åœ–ç‰‡ã€‚"""
        try:
            image_bytes = base64.b64decode(image_base64)
            filename = "generated_image.png"
            file_obj = nextcord.File(BytesIO(image_bytes), filename=filename)
            embed_obj = nextcord.Embed(
                color=nextcord.Color.green(),
                title="ðŸ–¼ï¸ ç”Ÿæˆå®Œæˆ",
                description=f"æç¤ºè©ž: {prompt}",
                timestamp=datetime.datetime.now(),
            )
            embed_obj.set_image(url=f"attachment://{filename}")
            embed_obj.set_footer(text="Images generated via Responses API")
            await interaction.edit_original_message(
                content=f"{interaction.user.mention}\n{text}", file=file_obj, embed=embed_obj
            )
        except Exception as e:
            logfire.warning(f"Failed to display final image: {e}")

    @nextcord.slash_command(
        name="clear_memory",
        description="Clear your conversation memory with the bot.",
        name_localizations={Locale.zh_TW: "æ¸…é™¤è¨˜æ†¶", Locale.ja: "ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢"},
        description_localizations={
            Locale.zh_TW: "æ¸…é™¤ä½ èˆ‡æ©Ÿå™¨äººçš„å°è©±è¨˜æ†¶ã€‚",
            Locale.ja: "ãƒœãƒƒãƒˆã¨ã®ä¼šè©±ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™ã€‚",
        },
        dm_permission=True,
        nsfw=False,
    )
    async def clear_memory(self, interaction: Interaction) -> None:
        """æ¸…é™¤ç”¨æˆ¶çš„å°è©±è¨˜æ†¶ã€‚

        Args:
            interaction (Interaction): The interaction object for the command.
        """
        user_id = interaction.user.id
        had_memory = self.user_last_response_id.pop(user_id, None) is not None

        if had_memory:
            await interaction.response.send_message(
                content="å°è©±è¨˜æ†¶å·²æ¸…é™¤! ä¸‹æ¬¡å°è©±å°‡é‡æ–°é–‹å§‹ã€‚", ephemeral=True
            )
        else:
            await interaction.response.send_message(
                content="ä½ ç›®å‰æ²’æœ‰å°è©±è¨˜æ†¶éœ€è¦æ¸…é™¤ã€‚", ephemeral=True
            )


async def setup(bot: commands.Bot) -> None:
    """Register the reply generation cog with the bot.

    Args:
        bot (commands.Bot): The bot instance to which the cog will be added.
    """
    bot.add_cog(ReplyGeneratorCogs(bot), override=True)
