from io import BytesIO
import base64
import datetime

from openai import BadRequestError
import logfire
import nextcord
from nextcord import Locale, Interaction, SlashOption
from nextcord.ext import commands
from openai.types.responses import Response
from openai.types.responses.tool_param import ImageGeneration
from openai.types.responses.web_search_tool_param import WebSearchToolParam

from discordbot.sdk.llm import LLMSDK

available_models = [
    "openai/gpt-4o",
    "openai/gpt-5-mini",
    "openai/gpt-5-nano",
    "claude-3-5-haiku-20241022",
]
MODEL_CHOICES = {available_model: available_model for available_model in available_models}


class ReplyGeneratorCogs(commands.Cog):
    def __init__(self, bot: commands.Bot) -> None:
        """Initialize the ReplyGeneratorCogs.

        Args:
            bot (commands.Bot): The bot instance.
        """
        self.bot = bot
        # å„²å­˜æ¯å€‹ç”¨æˆ¶çš„ä¸Šä¸€å€‹ response IDï¼Œç”¨æ–¼å°è©±è¨˜æ†¶
        self.user_last_response_id: dict[int, str] = {}

    def extract_image(self, responses: Response) -> bytes | None:
        image_data: list[str] = []
        for output in responses.output:
            if output.type == "image_generation_call":
                result = output.result
                if isinstance(output.result, str):
                    image_data.append(result)

        image_bytes = None
        if image_data:
            image_bytes = base64.b64decode(image_data[0])
        return image_bytes

    async def _get_attachment_list(
        self, messages: list[nextcord.Message] | None = None
    ) -> list[str]:
        """Retrieve all attachments from a message.

        This function extracts image attachment URLs, embed descriptions, and converts sticker images to base64 encoded strings. If the message is None, an empty list is returned.

        Args:
            messages (Optional[list[nextcord.Message]]): The message from which to extract attachments.

        Returns:
            List[str]: A list containing the attachment URLs and base64 encoded sticker images.
        """
        if messages is None:
            messages = []
        attachments: list[str] = []
        for message in messages:
            if message.attachments:
                _attach = [attachment.url for attachment in message.attachments if attachment.url]
                if _attach:
                    attachments.extend(_attach)
            if message.embeds:
                _attach = [embed.description for embed in message.embeds if embed.description]
                if _attach:
                    attachments.extend(_attach)
            if message.stickers:
                _attach = [sticker.url for sticker in message.stickers]
                if _attach:
                    attachments.extend(_attach)
        return attachments

    @nextcord.slash_command(
        name="oai",
        description="Generate a reply based on the given prompt.",
        name_localizations={Locale.zh_TW: "ç”Ÿæˆæ–‡å­—", Locale.ja: "ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"},
        description_localizations={
            Locale.zh_TW: "æ ¹æ“šæä¾›çš„æç¤ºç”Ÿæˆå›žè¦†ã€‚",
            Locale.ja: "æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ã„ã¦å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚",
        },
        dm_permission=True,
        nsfw=False,
    )
    async def oai(
        self,
        interaction: Interaction,
        prompt: str = SlashOption(
            description="Enter your prompt.",
            description_localizations={
                Locale.zh_TW: "è«‹è¼¸å…¥æç¤ºè©žã€‚",
                Locale.ja: "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
            },
        ),
        model: str = SlashOption(
            description="Choose a model (default: GPT-5).",
            description_localizations={
                Locale.zh_TW: "é¸æ“‡æ¨¡åž‹ (é è¨­ç‚º GPT-5)",
                Locale.ja: "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠžã—ã¦ãã ã•ã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ GPT-5ï¼‰",
            },
            choices=MODEL_CHOICES,
            required=False,
            default=available_models[0],
        ),
        image: nextcord.Attachment | None = SlashOption(  # noqa: B008
            description="(Optional) Upload an image.",
            description_localizations={
                Locale.zh_TW: "ï¼ˆå¯é¸ï¼‰ä¸Šå‚³ä¸€å¼µåœ–ç‰‡ã€‚",
                Locale.ja: "ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
            },
            required=False,
        ),
    ) -> None:
        """Generate a reply based on the user's prompt.

        If the model 'o1' is selected along with an image, an error message is returned since 'o1' does not support image input.
        The function can either generate a complete response or stream the response in real-time based on the stream parameter.

        Args:
            interaction (Interaction): The interaction object for the command.
            prompt (str): The prompt text provided by the user.
            model (str): The selected model, defaults to "gpt-5" if not specified.
            image (Optional[nextcord.Attachment]): An optional image attachment uploaded by the user.
        """
        await interaction.response.defer()
        attachments = []
        if model not in ["o1", "o1-mini"] and image:
            attachments.append(image.url)

        await interaction.followup.send(content="Thinking...")

        try:
            llm_sdk = LLMSDK(model=model)
            content = await llm_sdk.prepare_response_content(
                prompt=prompt, attachments=attachments
            )
            try:
                # ç²å–ç”¨æˆ¶çš„æœ€æ–° response ID
                previous_response_id = self.user_last_response_id.get(interaction.user.id, None)
                responses = await llm_sdk.client.responses.create(
                    model=model,
                    tools=[
                        WebSearchToolParam(type="web_search_preview"),
                        ImageGeneration(type="image_generation"),
                    ],
                    input=[{"role": "user", "content": content}],
                    previous_response_id=previous_response_id,
                )
            except BadRequestError:
                # å¦‚æžœ API å›žå‚³éŒ¯èª¤ï¼ˆresponse ID ç„¡æ•ˆï¼‰ï¼Œæ¸…ç†è©²ç”¨æˆ¶è¨˜éŒ„ä¸¦é‡æ–°å˜—è©¦
                self.user_last_response_id.pop(interaction.user.id, None)
                responses = await llm_sdk.client.responses.create(
                    model=model,
                    tools=[
                        WebSearchToolParam(type="web_search_preview"),
                        ImageGeneration(type="image_generation"),
                    ],
                    input=[{"role": "user", "content": content}],
                )

            # å„²å­˜æ–°çš„ response ID
            self.user_last_response_id[interaction.user.id] = responses.id

            await interaction.edit_original_message(
                content=f"{interaction.user.mention}\n{responses.output_text}"
            )

            image_bytes = self.extract_image(responses)
            if image_bytes:
                filename = "generated_image.png"
                file_obj = nextcord.File(BytesIO(image_bytes), filename=filename)
                embed_obj = nextcord.Embed(
                    color=nextcord.Color.blurple(),
                    title="ðŸ–¼ï¸ ç”Ÿæˆçš„åœ–ç‰‡",
                    description=f"æç¤ºè©ž: {prompt}",
                    timestamp=datetime.datetime.now(),
                )
                embed_obj.set_image(url=f"attachment://{filename}")
                embed_obj.set_footer(text="Images generated via Responses API")
                await interaction.edit_original_message(
                    content=f"{interaction.user.mention}\n{responses.output_text}",
                    file=file_obj,
                    embed=embed_obj,
                )

        except Exception as e:
            await interaction.edit_original_message(content=f"{e}")
            logfire.error("Error in oai", _exc_info=True)

    @nextcord.slash_command(
        name="clear_memory",
        description="Clear your conversation memory with the bot.",
        name_localizations={Locale.zh_TW: "æ¸…é™¤è¨˜æ†¶", Locale.ja: "ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢"},
        description_localizations={
            Locale.zh_TW: "æ¸…é™¤ä½ èˆ‡æ©Ÿå™¨äººçš„å°è©±è¨˜æ†¶ã€‚",
            Locale.ja: "ãƒœãƒƒãƒˆã¨ã®ä¼šè©±ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™ã€‚",
        },
        dm_permission=True,
        nsfw=False,
    )
    async def clear_memory(self, interaction: Interaction) -> None:
        """æ¸…é™¤ç”¨æˆ¶çš„å°è©±è¨˜æ†¶ã€‚

        Args:
            interaction (Interaction): The interaction object for the command.
        """
        user_id = interaction.user.id
        had_memory = self.user_last_response_id.pop(user_id, None) is not None

        if had_memory:
            await interaction.response.send_message(
                content="å°è©±è¨˜æ†¶å·²æ¸…é™¤! ä¸‹æ¬¡å°è©±å°‡é‡æ–°é–‹å§‹ã€‚", ephemeral=True
            )
        else:
            await interaction.response.send_message(
                content="ä½ ç›®å‰æ²’æœ‰å°è©±è¨˜æ†¶éœ€è¦æ¸…é™¤ã€‚", ephemeral=True
            )


async def setup(bot: commands.Bot) -> None:
    """Register the reply generation cog with the bot.

    Args:
        bot (commands.Bot): The bot instance to which the cog will be added.
    """
    bot.add_cog(ReplyGeneratorCogs(bot), override=True)
